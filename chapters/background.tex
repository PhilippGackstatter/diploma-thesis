\chapter{Background}

In this chapter we establish a common background for serverless computing and WebAssembly.

\section{Serverless computing}

\section{Serverless workload}

\citeauthor{Shahrad2020} have characterized the serverless workload at a large cloud-provider, Microsoft Azure. Because of their large number of users, this study can be considered very representative of the average workload.
They find that on average 81\% of the functions are invoked less than once per minute. However, those accessed more frequently make up 99.6\% of all invocations \cite{Shahrad2020}.
Those frequently accessed functions should thus be kept in memory, to avoid the cold start entirely. The less frequently accessed functions should not be kept in memory, but created, executed and destroyed immediately, in order to save resources. For this to be viable, the cold-start needs to be a cheap operation. In general, the cheaper the cold start, the smaller the amount of time that functions need to be kept in memory.

\citeauthor{Shahrad2020} also find that on average, 50\% of functions execute for less than one second.

\begin{quote}
    \quot{The main implication is that the function execution times are at the same order of magnitude as the cold start times reported for major providers. \emph{This makes avoiding and/or optimizing cold starts extremely important for the overall performance of a FaaS offering} \cite{Shahrad2020}.}
\end{quote}

Because of that, the primary goal in this work is that of reducing the cold start latency, to make that first function invocation less costly. However, we also need to make sure that what we have a resource-efficient way to keep the function in memory, since the most frequently accessed ones make up the overwhelming share of invocations and cold starting them would be even more costly. Thus we also investigate the resource usage of WebAssembly modules in memory.

\section{WebAssembly}

% - origins (asm.js)
% - first implemnted in browsers, targeted at web
% - but standalone runtimes exist, similar to V8 which was the node.js runtime for Chrome and later became node.js
% - now also used at cloud service providers for serverless functions (fastly, cloudflare) and as the VM for smart contracts implementation, for instance in IOTA. In all three of these cases security is quite important, as untrusted code is executed.
% - security properties of Wasm
% - Finally, speed is also important (whole reason why asm.js was made in the first place)
% - to use outside of the browser, need a interface to the OS, the task that is done by the browser on the web platform

For the longest time, JavaScript was the sole client-side language in web browsers. With the rising popularity of the web platform, more and more programming languages could be used to write web apps. Necessarily, these languages had to use JavaScript as a target format like Java Bytecode or machine-level assembly. JavaScript of course wasn't designed for this, so performance was lacking.

In 2013 a solution to this problem was introduced by engineers at Mozilla, aptly named \inl{asm.js}. It restricts itself to the parts of JavaScript that can be optimized ahead-of-time \cite{Herman2014}. Thus it might be used to compile a C/C++ program to the \inl{asm.js} target format to execute it faster with a JavaScript runtime than the equivalent JavaScript program would be. Benchmarks even showed it to run no more than 1.5x slower than native code \cite{Zakai2013}.

Finally, WebAssembly (Wasm) was born out of \inl{asm.js} in 2015, with more layers of optimization. Compared to \inl{asm.js}, the Wasm binary format is smaller in size (10-20\%) and faster to parse (by an order of magnitude).
Since it is a bytecode format independent from JavaScript, it requires a separate runtime and sandboxing mechanism.

In summary, Wasm is a portable and universal binary instruction format for memory-safe, sandboxed execution in a virtual machine \cite{W3C2020}.
